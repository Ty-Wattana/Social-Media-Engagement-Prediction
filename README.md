# Social-Media-Engagement-Prediction
This repository is part of a group project in the Fundamental Programming class at Chulalongkorn University.
The full presentation file can be found on https://docs.google.com/presentation/d/1lmhuRpuyOUaLFmF3sizkuizpkVzOZf_-7e9D8FYarKw/edit?usp=sharing


In this project, we try to build a model that can explain the relationship between the characteristic of the tweets and it's engagement. The data science question for this project is that "What are factors that influence tweeter engagement?". The insight from this study may be useful for Marketers/Influencer, Content Creator, Journalists, Politician,s or those who want to gain the most tweeter engagement.

The project's procedure follows CRISP-DM data science methodology which includes 4 essential steps. (1) Business Understanding (2) Collecting Explore and Prepare Data (3) Modelling (4) Deployment and Presentation.

  (1) Business Understanding: We identify the data science question and stakeholders as mentioned above. We also the data source necessary for the project which is Tweeter API and we only collect the data for those accounts with high engagement.
  
  (2) Collecting Explore and Prepare Data: We develop a code to retrieve data from Twitter API. The code can be found in the "Twitter API-Specific-media.ipynb" file. The data includes 15 columns namely "Date", "ID", "Name", "Text", "Hashtags", "User Mentions", "Symbols", "Media", "Source", "Location", "Follower count", "Friends count", "Favorite count", "Retweet count" and "Status count". We also perform the data exploration and preparation in the file "EDA.ipynb". The essential insight from the data exploration is that our data set contains many reply tweets that are not in the scope of this project. We also found that the data is very skewed to the right. In the preparation process, we try to get rid of those reply tweets by dropping rows that the "Text" column contains a string that starts with user mention (i.e. @ sign) and has engagement less than 10. We also remove some columns that unnecessary for the model (ID, Name, Location, Symbols, Source). We also perform feature extraction in this stage. The essential feature extraction including define target variable (Engagement) as the sum of "Favorite count" and "Retweet count", count the number of hashtags, emoji, user mention as one feature, convert time variable to categorical variable and vectorize the text of each tweets using count vectorization.
  
  (3) Modelling: We start by training a simple linear regression model ("twitter_modeling.ipynb") but we encounter multiple problems namely low R square and low prediction accuracy. Then we switch to the classification model where we classify engagement into 4 groups according to their respective quantiles ("twitter_modeling-Classification.ipynb" and "Classification modelingV2.ipynb"). We found that the Random Forrest modeling is promising since it shows the highest accuracy score among the others. Then we decide to revisit our regression model but utilize the Random Forrest algorithm ("Tweeter_model(Edited 03-05-2021).ipynb"). We eliminate some outliners and train the Random Forrest regression. We also perform parameter tuning using grid search. The final model has a test set R square of  0.59. The Random Forrest regression gives us the important feature score indicating which features are more important in explaining the relationship. The top 5 most important features including Follower count, User-mention count, Status count Friend count, and dummy Industries_singer (whether the account is a singer or not)
  
  (4) deployment and Presentation: We deploy this work and conclusion in this Github repository and the full presentation deck can be found on https://docs.google.com/presentation/d/1lmhuRpuyOUaLFmF3sizkuizpkVzOZf_-7e9D8FYarKw/edit?usp=sharing
